{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Wk3_Linear_Regression.ipynb.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression with sklearn API"
      ],
      "metadata": {
        "id": "BWtA2iTSqzwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Build linear regression model with sklearn.\n",
        "\n",
        "1. Dataset: California housing\n",
        "2. Linear Regression API: LinearRegression\n",
        "3. Training: fit(normal eq) and cross_validate(normal with cross validate)\n",
        "4. Evaluation: score (r2 score) and cross_val_score with different scoring parameters\n",
        "\n",
        "We will study the model diagnosis with LearningCurve and learn how to examine the learned model or weight vector"
      ],
      "metadata": {
        "id": "YdlYYbIkwis2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9Yd7Jyzqbhr"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.linear_model LinearRegression\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(306)\n",
        "plt.style.use('seaborn')"
      ],
      "metadata": {
        "id": "sGjj5hBaxoEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use ShuffleSplit cross validate with:\n",
        "\n",
        "* 10 folds (n_splits) and\n",
        "* set aside 20% examples as test examples (test_size)\n"
      ],
      "metadata": {
        "id": "mSG6d8zdxugS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_split_cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "rZhAz0MTx6h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates 10 folds through shuffle split by keeping aside 20% examples as test in each fold."
      ],
      "metadata": {
        "id": "EWyslMBDyDJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Load the dataset"
      ],
      "metadata": {
        "id": "I6F7kKfRyJh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)"
      ],
      "metadata": {
        "id": "vHMCkEiNyM0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The feature matrix is loaded in features dataframe and the labels dataframe. Let's examine the shapes of these two dataframes."
      ],
      "metadata": {
        "id": "DLFlFsXDyVxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape, labels.shape)"
      ],
      "metadata": {
        "id": "Gj_tAVzHyeiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Data Exploration\n",
        "\n",
        "Covered in separate notebook"
      ],
      "metadata": {
        "id": "LQlj_Hy3yvV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STEP 3: Preprocessing and model building"
      ],
      "metadata": {
        "id": "dFJgt6O3y1rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Train test split\n",
        "\n",
        "The first step is to split the data into training and test"
      ],
      "metadata": {
        "id": "nM75cad5y7C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features,labels,random_state=42)\n"
      ],
      "metadata": {
        "id": "jwEcITO0zCsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine the shapes"
      ],
      "metadata": {
        "id": "eoi3g2TazWt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features.shape, test_features.shape)"
      ],
      "metadata": {
        "id": "khD8vNJGzZXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Pipeline preprocessing+model\n",
        "\n",
        "1. StandardScaler\n",
        "2. LinearRegression"
      ],
      "metadata": {
        "id": "522DxDLYziNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_pipeline = Pipeline([('feature_scaling',StandardScaler()),\n",
        "                             ('lin_reg',LinearRegression())])\n",
        "lin_reg_pipeline.fit(train_features, train_labels)"
      ],
      "metadata": {
        "id": "jdDDT4sMz0lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the learnt weight vectors"
      ],
      "metadata": {
        "id": "D1g78z3EzvIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lin_reg_pipeline[-1].intercept_,lin_reg_pipeline[-1].coef_)"
      ],
      "metadata": {
        "id": "DGjkCaMi0MuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Model Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "aY3mAAit0XWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Score\n",
        "\n",
        "With twin objectives\n",
        "\n",
        "* Estimation of model performance\n",
        "* Comparison of errors for model diagnostics"
      ],
      "metadata": {
        "id": "vRH3FQQS1oS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = lin_reg_pipeline.score(test_features, test_labels)\n",
        "print(test_score)\n",
        "train_score = lin_reg_pipeline.score(train_features, train_labels)\n",
        "print(train_score)"
      ],
      "metadata": {
        "id": "MGQ3uNzP06Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score method returns r2 score whose best value is 1."
      ],
      "metadata": {
        "id": "HSqO7SLA1aqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crss validated score"
      ],
      "metadata": {
        "id": "WcsoKASh1hMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_score = cross_val_score(lin_reg_pipeline,\n",
        "                                train_features,\n",
        "                                train_labels,\n",
        "                                scoring='neg_mean_squared_error',\n",
        "                                cv=shuffle_split_cv)\n",
        "\n",
        "print(lin_reg_score)"
      ],
      "metadata": {
        "id": "ofr8rNUm1xpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we got negative errors, we can convert that as follows"
      ],
      "metadata": {
        "id": "m3x4O17w2L0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_mse = -lin_reg_score"
      ],
      "metadata": {
        "id": "K3hXsJKQ2Uoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use other scoring parameters, choices are as below:\n",
        "\n",
        "* explained_variance\n",
        "* max_error\n",
        "* neg_mean_absolute_error\n",
        "* neg_root_mean_squared_error\n",
        "* neg_mean_squared_log_error\n",
        "* neg_median_absolute_error\n",
        "* neg_mean_absolute_percentage_error\n",
        "* r2"
      ],
      "metadata": {
        "id": "UA-6wEGU2ben"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation\n",
        "\n",
        "To access the models trained in each fold along with some other stats"
      ],
      "metadata": {
        "id": "XuyE3RoD22l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_cv_results = cross_validate(lin_reg_pipeline,\n",
        "                                    train_features,\n",
        "                                    train_labels,\n",
        "                                    cv=shuffle_split_cv,\n",
        "                                    scoring='neg_mean_squared_error',\n",
        "                                    return_train_score,\n",
        "                                    return_estimator=True)"
      ],
      "metadata": {
        "id": "u8A9aSeT3G_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lin_reg_cv_results is a dictionary with following contents:\n",
        "\n",
        "* trained estimators,\n",
        "* time taken for fitting and scoring the models in cv,\n",
        "* training score\n",
        "* test scores"
      ],
      "metadata": {
        "id": "W1YOVarS3aYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_cv_results"
      ],
      "metadata": {
        "id": "JjeVNUCP3n4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 values for cv=10"
      ],
      "metadata": {
        "id": "d3DYPi1r3pal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Examination\n",
        "\n",
        "Let's examine how much variability exists between the cross validated models"
      ],
      "metadata": {
        "id": "D6NsXkh-4HaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = train_features.columns\n",
        "feature_names"
      ],
      "metadata": {
        "id": "8v8QG3AT4Qnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefs = [est[-1].coef_ for est in lin_reg_cv_results['estimator']]\n",
        "weights_df = pd.DataFrame(coefs, columns=feature_names)\n",
        "\n",
        "color = {'whiskers':'black','medians':'black','caps':'black'}\n",
        "weights_df.plot.box(color=color,vert=False)\n",
        "_=plt.title('Linear Regression Coefficients')"
      ],
      "metadata": {
        "id": "-GuMhfDx4e0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_df.describe()"
      ],
      "metadata": {
        "id": "M2EFKpqc5Khy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting best model\n",
        "\n"
      ],
      "metadata": {
        "id": "Cj2Zs_4F4eLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_index = np.argmin(test_error)\n",
        "selected_model = lin_reg_cv_results['estimator'][best_model_index]"
      ],
      "metadata": {
        "id": "rEQ0NZ5g5oiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Performance"
      ],
      "metadata": {
        "id": "8_YC9tAG6EH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "cv_predictions = cross_val_predict(in_reg_pipeline, train_features, train_labels)"
      ],
      "metadata": {
        "id": "a_-fYFa-6IKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_cv = mean_squared_error(train_labels,cv_predictions)\n",
        "\n",
        "plt.scatter(train_labels,cv_predictions, color='blue')\n",
        "plt.plot(train_labels,train_labels,'-r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qFED5kOV6U7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Predictions"
      ],
      "metadata": {
        "id": "q7_e14OG6wZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the best performing model from cross validation for getting predictions on the test set."
      ],
      "metadata": {
        "id": "CueWLchn6zMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_cv = selected_model.predict(test_features)\n",
        "test_predictions_cv[:5]"
      ],
      "metadata": {
        "id": "SYc4cq6r7DQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We cana also obtain predictions using the initial model that we built without cross validation."
      ],
      "metadata": {
        "id": "i-7Pma1y7Lse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions_cv = lin_reg_pipeline.predict(test_features)\n",
        "test_predictions_cv[:5]"
      ],
      "metadata": {
        "id": "tWXUiepB7SpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6: Report model performance"
      ],
      "metadata": {
        "id": "Hq-D0aS47XfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_cv = selected_model.score(test_features, test_labels)\n",
        "score = lin_reg_pipeline.score(test_features, test_labels)\n",
        "print(score_cv,score)"
      ],
      "metadata": {
        "id": "HrjGRyXf7eQZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}