{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Wk4_Binary_class_Image_Classification_with_Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "* To solve classfication problems we are going to consider image classfication as a running example and solving it using Perceptron() model."
      ],
      "metadata": {
        "id": "L2jSFAYqf8Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n",
        "First Step:\n",
        "\n",
        "* import all necessary packages, For classification problems, we need to import classes and utilities from sklearn.linear_model\n",
        "  * This module has implementations for different classification models like Perceptron, LogisticRegression, svm and knn.\n",
        "\n",
        "We also need to import a bunch f model selection utilities from sklearn.model_selection module and metrics from sklearn.metrics module.\n",
        "\n",
        "The data preprocessing utilities are imported from sklearn.preprocessing modules."
      ],
      "metadata": {
        "id": "XvZnGgWZgNoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvipETWVfbWq"
      },
      "outputs": [],
      "source": [
        "#common\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import warnings\n",
        "\n",
        "#sklearn specific imports\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import hinge_loss\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_validate, cross_val_predict, GridSearchCV\n",
        "\n",
        "#for pretty printing\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit Classification\n",
        "\n",
        "* We are going to use perceptron classifier to classify given digit images. Since a single perceptron could only be used for binary classfification, we consider only two classes in first half. Eventualy we extend it to multiclass setting.\n",
        "\n",
        "* Suppose we want to recognize whether the given image is of digit zero or not (digits other than zero). Then the problem could be cast as a binary classification problem.\n",
        "\n",
        "* The first step is to create a dataset that contains a collection of digit images written by humans. Then each image should be labelled properly.\n",
        "\n",
        "* Fortunately, we have a standard benchmark dataset called MNIST, well, why not make use of it? Let's import data first..."
      ],
      "metadata": {
        "id": "z9UwMp1bh9FQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Splitting"
      ],
      "metadata": {
        "id": "sNkbG5qnkBAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = fetch_openml('mnist_784', version=1,return_X_y=True)\n",
        "\n",
        "# it returns Data and label as a pandas dataframe"
      ],
      "metadata": {
        "id": "o8w1toK-kDeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data matrix X and the respective label vector y need to be converted to the numpy array by calling a to_numpy method."
      ],
      "metadata": {
        "id": "IQ4FWJ1ckRGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "metadata": {
        "id": "gJolibw7keSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let's get some information like number of features, number of classes about the dataset.\n",
        "* Observe that the labels are of string data type not integers."
      ],
      "metadata": {
        "id": "xOJlvEg_ktUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = np.unique()\n",
        "print('Number of samples: {0}, type:{1}'.format(X.shape[0],X.dtype))\n",
        "print('Number of features: {0}'.format(X.shape[1]))\n",
        "print('Minimum: {0}, Maximum: {1}'.format(np.min(X),np.max(X)))\n",
        "print('Number of classes: {0}, type:{1}'.format(len(target_names),y.dtype))\n",
        "print('Labels: {0}'.format(target_names))"
      ],
      "metadata": {
        "id": "c7N2be13k6A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The MNIST dataset is clean and the range of values that each feature can take is also known. Therefore, the samples in the dataset may not require many data preprocessing techniques.\n",
        "\n",
        "* However, it is often better to scale many data preprocessing techiques.\n",
        "\n",
        "* So, we can either use MinMaxScaler or MaxAbsScaler. They don't make any difference as the image pixels can takes only positive values from 0 to 255."
      ],
      "metadata": {
        "id": "OPVn3dSUmVLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=MinMaxScaler().fit_transform(X)\n",
        "print('Minimum: {0}, Maximum: {}'.format(np.min(X),np.max(X)))"
      ],
      "metadata": {
        "id": "NmtzPxEQnrwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n",
        "\n",
        "Let us pick a few images (the images are already shuffled in the dataset) and display them with their respective labels. As said above, the images are stacked as a row vector of size 1 x 784 and therefore must be reshaped to the matrix of size 28 x 28 to display them properly."
      ],
      "metadata": {
        "id": "OFLtFkYBoURu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = 9\n",
        "factor = np.int(np.sqrt(num_images))\n",
        "fig, ax = np.subplots(nrows=factor, ncols=factor, figsize=(8,6))\n",
        "idx_offset = 0\n",
        "for i in range(factor):\n",
        "  index = idx_offset+i*(factor)\n",
        "  for j in range(factor):\n",
        "    ax[i,j].imshow(X[index+j].reshape(28,28), cmap='gray')\n",
        "    ax[i,j].set_title('Label: {0)'.format(str(y[index+j])))\n",
        "    ax[i,j].set_axis_off()"
      ],
      "metadata": {
        "id": "cRPAEnAPorXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you closely observe, you can see that there are moderate variations in the appearance of digits. These matrices are also close to sparse matrix."
      ],
      "metadata": {
        "id": "_C7tUlAR30bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting\n",
        "\n",
        "* Now we know the details such as number of samples, size of each sample, no of features (784), no of classes about the dataset.\n",
        "* So let us total no of samples into train and test set in the following ratio: 60000/10000\n",
        "* Since the samples in the data set are already randomly shuffled, we need not to shuffle it again. Therefore using train_test_split() may be skipped."
      ],
      "metadata": {
        "id": "M4r06cLD4DV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "metadata": {
        "id": "dlIbj6ef4f04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceeding further we need to check whether the dataset is balanced or imbalanced. We can do it bpy plotting the distribution of samples in each classes."
      ],
      "metadata": {
        "id": "ycyf0ygw4wkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize(10,4))\n",
        "sns.histplot(data=np.int8(y_train), binwidth=0.45,bins=11)\n",
        "plt.xticks(ticks=[0,1,2,3,4,5,6,7,8,9],labels=[0,1,2,3,4,5,6,7,8,9])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Dist of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1i9DVlvg5LWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification: 0-Detector"
      ],
      "metadata": {
        "id": "v89N8lHv5kaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifying Labels\n",
        "* Let us start with a simple classification problem, that is, binary classification.\n",
        "* Since the original label vector contains 10 classes, we need to modify the number of classes to 2.\n",
        "Therefore, the label 0 will be changed to 1 and all other labels (1-9) will be changed to -1.\n",
        "* We name the label vectors as y_train_0 and y_test_0"
      ],
      "metadata": {
        "id": "5iKA5phX5pKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize new variable name with all -1\n",
        "y_train_0 = -1*np.ones((len(y_train)))\n",
        "y_test_0 = -1*np.ones((len(y_test)))\n",
        "\n",
        "# find indices of digit 0 image\n",
        "indx_0 = np.where(y_train=='0') # remember original labels are of type str not int\n",
        "# use those indices to modify y_train_0 and y_test_0\n",
        "y_train_0[index_0] = 1\n",
        "indx_0 = np.where(y_test=='0')\n",
        "y_test_0[indx_0]=1"
      ],
      "metadata": {
        "id": "_-oyj4TC6FDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Models\n",
        "\n",
        "Enough about Data!\n",
        "\n",
        "Let us quickly construct a baseline model with the following rule,\n",
        "\n",
        "1. Count number of samples per class.\n",
        "2. The model always outputs the class which has highest number of samples.\n",
        "3. Then calculate the accuracy of the baseline model."
      ],
      "metadata": {
        "id": "iw8imS3aAqA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_pos = len(np.where(y_train_0==1)[0])\n",
        "num_neg = len(np.where(y_train_0==-11)[0])\n",
        "print(num_pos, num_neg)"
      ],
      "metadata": {
        "id": "dwoOmBPJBOHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_clf = DummyClassifier(strategy='most_frequent') # there are other strategies"
      ],
      "metadata": {
        "id": "BJmusG17BlQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_clf.fit(x_train, y_train_0)\n",
        "print('Training accuracy: {0:.2f}'.format(base_clf.score(x_train,y_train_0)))\n",
        "print('Testing accuracy: {0:.2f}'.format(base_clf.score(x_test,y_test_0)))"
      ],
      "metadata": {
        "id": "9tP1BtQSBot6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now the reason is obvious. The model would have predicted 54077 sample correctly just by outputing -1 for all the input samples. Therefore the accuracy will be 54077/60000 = 90.12%.\n",
        "* This is the reason why 'accuracy' alone is not always a good measure!"
      ],
      "metadata": {
        "id": "VG1EaX7jBeaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron model\n",
        "\n",
        "Before using Perceptron for Binary Classification, it will be helpful to recall the important concepts (equations) covered in technique course."
      ],
      "metadata": {
        "id": "NtZpq2l2CXsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters of Perceptron class\n",
        "\n",
        "* Let's quickly take a look into the important parameters of the Perceptron()\n",
        "\n",
        "class sklearn.linear_model.Perceptron(*,penalty=None,alpha=0.0001,l1_ratio=0.15,fit_intercept=True,max_iter=1000,tol=0.001,shuffle=True,verbose=0,eta0=1.0,n_jobs=None,randm_state=0,early_stopping=False,validation_fraction=0.1,n_iter_no_change=5,class_weight=None,warm_start=False)"
      ],
      "metadata": {
        "id": "moEE_hDkDJjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiation\n",
        "\n",
        "* Create an instance of binary classifier (bin_clf) and call fit method to train the model."
      ],
      "metadata": {
        "id": "hLsHRVYeD8Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf = Perceptron(max_iter=100, random_state=1729)"
      ],
      "metadata": {
        "id": "Hezj-T8pEECd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Prediction\n",
        "\n",
        "* Call the fit method to train the model.\n",
        "* It would be nice to plot the iteration vs loss curve for the training. However, sklearn does not have a direct function to plot it.\n",
        "* Nevertheless, we can workaround this using partial_fit method (which will be demonstrated at the end of the lecture)"
      ],
      "metadata": {
        "id": "bnWY4WoeELpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf.fit(x_train,y_train_0)\n",
        "print('Dimention of Weights w:'.format(bin_clf_.shape))\n",
        "print('Bias: {}'.format(bin_clf.intercept_))\n",
        "print('The loss function: {0}'.format(bin_clf.loss_function_))"
      ],
      "metadata": {
        "id": "F2yXKxfZF1TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us make predictions on the train set and then calculate the training accuracy."
      ],
      "metadata": {
        "id": "RDITBuYtGL8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_train_0 = bin_clf.predict(x_train)\n",
        "print('Training Accuracy: ', bin_clf.Score(x_train, y_train_0))"
      ],
      "metadata": {
        "id": "Ewfrh9CWGb-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Displaying predictions\n",
        "\n",
        "* Take few images from the testset at random and display it with the corresponding predictions.\n",
        "* Plot a few images in a single figure window along with their respective predictions."
      ],
      "metadata": {
        "id": "UZc8kZI7GqvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_test+0 = bin_clf.predict(x_test)\n",
        "num_images = 9\n",
        "factor = np.int(np.sqrt(num_images))\n",
        "fig, ax = plt.subplots(nrows=factor, ncols=factor, figsize=(8,6))\n",
        "idx_offset = 0\n",
        "for i in range(factor):\n",
        "  index = idx_offset+i*(factor)\n",
        "  for j in range(factor):\n",
        "    ax[i,j].imshow(x_test[index+j].reshape(28,28),cmap='gray')\n",
        "    ax[i,j].set_title('Prediction: {0}'.format(str(y_hat_test_0[index+j])))\n",
        "    ax[i,j].set_axis_off()"
      ],
      "metadata": {
        "id": "exgqbiimG7LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that there are a significant number of images that are correctly classified. Let's see how many?"
      ],
      "metadata": {
        "id": "eOl8CuvDN8gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_misclassified = np.count_nonzero(zeroLabs=-1)\n",
        "num_correctpred = len(zeroLabls)-num_misclassified\n",
        "accuracy = num_correctpred/len(zeroLabls)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "E4DpRa4-OEDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This above score is less than the accuracy score of the model but it seems preety descent!\n",
        "* Will it be the same if we consider an other digit, say, 5 for positive class and all other class as negative?.. Of course not. You may cross check it."
      ],
      "metadata": {
        "id": "URcIbL_POuC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Better Evaluation metrics\n",
        "\n",
        "* We now know that using the accuracy alone to measure the performance of the model is not suitable (especially for imbalanced datasets), so which are the more suitable metrics then?"
      ],
      "metadata": {
        "id": "8sgBhB0zPiKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix"
      ],
      "metadata": {
        "id": "KYaf4t-jQz2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_train_0 = bin_clf.predict(x_train)\n",
        "cm_display = ConfusionMatrixDisplay.from_predictions(y_train_0, y_hat_train_0, values_format='.5g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U8kMNmHgQ2tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Pay attention to the number of FPs and FNs. Suppose for some reasons, we want the classifier to avoid FPs to a good extent of FNs, how can we achieve it?\n",
        "* To answer it, let's compute the other metrics which take FPs and FNs into account."
      ],
      "metadata": {
        "id": "HkH_j0iIRHlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precision and Recall"
      ],
      "metadata": {
        "id": "XZk4uIIIRmUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We an use the function classification_report to compute these parameters. However, for the time being let's compute these parameters using the data from the confusion matrix manually (not a difficult thing to do, right?)"
      ],
      "metadata": {
        "id": "aO5NMwRaRpB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = cm.display.confusion_matrix\n",
        "tn = cf_matrix[0,0]\n",
        "fn = cf_matrix[1.0]\n",
        "fp = cf_matrix[0,1]\n",
        "tp = cf_matrix[1,1]"
      ],
      "metadata": {
        "id": "Rr4h-J7rR6cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tp/(tp+fp)\n",
        "print('Precisions: ', precision)\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall: ', recall)\n",
        "accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
        "print('Accuracy: ', accuracy)"
      ],
      "metadata": {
        "id": "Qb9MECt5SQZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The precision is close to 0.98. Despite it, we still want to increase the precision. Let's come back to this later.\n",
        "* In general, we would like to know whether the model under consideration with the set hyper-parameters is a good one for a given problem."
      ],
      "metadata": {
        "id": "xTZBbiYzSob6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation\n",
        "\n",
        "* Well to address this, we have to use cross-validation folds and measure the same metrics across these folds for different values of hyper-parameters.\n",
        "* However perceptron does not have many hyperparameters other than the learning rate.\n",
        "* For the moment, we set the learning rate to its default value. Later we use GridSearchCV to find the better value for the learning rate."
      ],
      "metadata": {
        "id": "D9VJQ_UxS7I-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf = Perceptron(max_iter=100, random_state=1729)\n",
        "scores = cross_validation(bin_clf, x_train, y_train_0, cv=5,\n",
        "                          scoring=['precision','recall','f1'],\n",
        "                          return_estimator=True)\n",
        "pprint(scores)"
      ],
      "metadata": {
        "id": "O2b30iZqVcqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note\n",
        "The perceptron estimator passed as an arguement to the function cross_validate is internally cloned num_fold (cv=5) times and fitted independently on each fold. (you can check this by setting warm_start=True)\n",
        "* Compute the average and standard deviation of scores for all three metrics on k=5 folds to measure the generalization."
      ],
      "metadata": {
        "id": "AGR3kxzUVz_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('f1,        avg:{0:.2f}, std:{1:.3f}'.format(scores['test_f1'].mean(),scores['test_f1'].std()))\n",
        "print('precision, avg:{0:.2f}, std:{1:.2f}'.format(scores['test_precision'].mean(),scores['test_precision'].std()))\n",
        "print('recall,    avg:{0:.2f}, std:{1:.2f}'.format(scores['test_recall'].mean(),scores['test_recall'].std()))"
      ],
      "metadata": {
        "id": "rkYNMAkMWRq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let us pick the first estimator returned by the cross_validate function.\n",
        "* So we can hope that the model might also perform well on the test data. Let's check that out."
      ],
      "metadata": {
        "id": "L0teOnmtYh9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf = scores['estimator'][0]\n",
        "y_hat_test_0 = bin_clf.predict(x_test)\n",
        "cm_display = ConfusionMatrixDisplay().from_predictions(y_test_0,y_hat_test_0,values_format='.5g')\n",
        "cm_display = ConfusionMatrixDisplay.from_predictions(y_test_0,y_hat_test_0,values_format='.5g')"
      ],
      "metadata": {
        "id": "8Ij5nVA6Y5-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Precision %.2f'%precision_score(y_test_0,y_hat_test_0))\n",
        "print('Recall %.2f'%recall_score(y_test_0,y_hat_test_0))"
      ],
      "metadata": {
        "id": "I9f9sviHbNdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is good!"
      ],
      "metadata": {
        "id": "Nb4wSU3Kbat5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Way-2 for Generalization:\n",
        "(Optional)\n",
        "\n",
        "* There is another approach of getting predicted labels via cross-validation and using it to measure the generalization.\n",
        "* In this case, each sample in the dataset will be part of only one test set in the splitted folds."
      ],
      "metadata": {
        "id": "tJarkYglbcY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_train_0 = cross_val_predict(bin_clf, x_train, y_train_0, cv=5)"
      ],
      "metadata": {
        "id": "qj8WFON4b3YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_display = ConfusionMatrixDisplay.from_predictions(y_train_0, y_hat_train_0, values_format='.5g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zMDGkg1EiUTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = cm_display.confusion_matrix\n",
        "tn = cf_matrix[0,0]\n",
        "fn = cf_matrix[1.0]\n",
        "fp = cf_matrix[0,1]\n",
        "tp = cf_matrix[1,1]"
      ],
      "metadata": {
        "id": "mU4Yf1-zisFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tp/(tp+fp)\n",
        "print('Precisions: ', precision)\n",
        "recall = tp/(tp+fn)\n",
        "print('Recall: ', recall)\n",
        "accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
        "print('Accuracy: ', accuracy)"
      ],
      "metadata": {
        "id": "BxyJXGuvi148"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Compare the precision and recall score obtained by the above method with that of the previous method\n",
        "* Finally, we can print all these scores as a report using the classification_report function"
      ],
      "metadata": {
        "id": "_6QnGTWKi4Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Precision %.2f'%precision_score(y_test_0,y_hat_test_0))\n",
        "print('Recall %.2f'%recall_score(y_test_0,y_hat_test_0))\n",
        "print('-'*50)\n",
        "print(classification_report(y_train_0,y_hat_train_0))"
      ],
      "metadata": {
        "id": "RiCKWQn4jEmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precision/Recall Tradeoff\n",
        "\n",
        "* Often time we need to make a trade off between precision and recall scores of a model.\n",
        "* It depends on the problem at hand.\n",
        "* It is important to note that should not pass the predicted labels as input to precision_recall_curve function, instead we need to pass the probability scores or the output from the decision function!\n",
        "* The Perceptron() class contains a decision_function method, therefore we can make use of it.\n",
        "* Then, internally the decision scores are sorted, tps and fps will be computed by changing the threshold from index[0] to index[-1].\n",
        "* Let us compute the scores from the decision function."
      ],
      "metadata": {
        "id": "Y1iZW72EjTit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf = Perceptron(random_state=1729)\n",
        "bin_clf.fit(x_train, y_train_0)\n",
        "y_scores = bin_clf.decision_function(x_train)\n",
        "sns.histplot(np.sort(y_scores))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZZ0UGrEMl2WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you think why there are so many negative values than the positives?\n",
        "\n",
        "Hint: Class-Imbalance\n",
        "\n",
        "* Suppose threshold takes the value of -600, then all the samples having score greater than -600 is set to 1(+ve label) and less than it is set to -1(neg label).\n",
        "* Therefore, the number of False Positives will be increased. This wll in turn reduce the precision score to a greater extent.\n",
        "* On the otherhand, if the threshold takes the value of, say 400. Then, the number of false negatives will be increase ad hence the recall will reduce to a greater extent.\n",
        "* Let's see it in action."
      ],
      "metadata": {
        "id": "Kxi1a6xhmWKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recalls, thresholds = precision_recall_curve(y_train_0, y_scores, pos_label=1)"
      ],
      "metadata": {
        "id": "gJ2SB_n7nGh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(precision[:-1], recalls[:-1], 'b--')\n",
        "plt.xlabel('Precision')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l_4-cajonmKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the index of threshold around zero\n",
        "idx_th = np.where(np.logical_and(threshold>0,thresholds<1))\n",
        "print('precision for zero threshold: ', precisions[idx[0][0]])"
      ],
      "metadata": {
        "id": "fcQEj6bXoN-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here is the solution: to the question how can we increase the precision of the classifier by compromising the recall, we can make use of the above plot.\n",
        "* Let's see how"
      ],
      "metadata": {
        "id": "QSiIB-dToh5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The ROC Curve"
      ],
      "metadata": {
        "id": "hdfDKiK0o83J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve"
      ],
      "metadata": {
        "id": "Bw_gXIUmo_xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_train_0, y_scores)\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(fpr,tpr,linewidth=2,label='Perceptron')\n",
        "plt.plot([0,1], [0,1], 'k--', label='baseEstimator')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gSYk80ncpDxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Warm Start vs Cold Start"
      ],
      "metadata": {
        "id": "C18wXoA0pybr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cold Start\n",
        "\n",
        "* If we execute the fit method of bin_clf repeatedely, we get the same score for both training and testing accuracy.\n",
        "* This because every time the fit method is called, the model weights are initialized to the same values. Therefore, we obtain the same score.\n",
        "* This is termed as cold start. Let's execute the following cell 4 times and observe the score."
      ],
      "metadata": {
        "id": "hbn9jFnXp1bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf.fit(x_train, y_train_0)\n",
        "y_hat_train_0 = bin_clf.predict(x_train)\n",
        "print('Training Accuracy: ', bin_clf.score(x_train,y_train_0))\n",
        "print('Test Accuracy: ', bin_clf.score(x_test,y_test_0))"
      ],
      "metadata": {
        "id": "psQFOoItqShP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warm Start\n",
        "\n",
        "* As you might have guessed, there is an approach called Warm Start\n",
        "* Setting warm_start=True retains the weight values of the model after max_iter and hence produce different results for each execution.\n",
        "* Warm setting is useful in many ways. It helps us train the model by initializing the weight values from the previous state. So we can pause the training and resume it whenever we get the resource for computation.\n",
        "* Of course, it is not required for simple models like perceptron and for a small dataset like MNIST\n",
        "* In this notebook, we use this feature to plot the iteration vs loss curve.\n",
        "* Let us execute the following lines of code 4 times and observe how the training accuracy changes for each execution."
      ],
      "metadata": {
        "id": "BpsIdzf8xKfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf_warm = Perceptron(max_iter=100, random_state=1729, warm_start=True)"
      ],
      "metadata": {
        "id": "xKKCp2ALzcc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_clf_warm.fit(x_train, y_train_0)\n",
        "print('Training Accuracy:', bin_clf_warm.score(x_train,y_train_0))"
      ],
      "metadata": {
        "id": "gU57Te-AzlUv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}